{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content='Hi Aden! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 33, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CVHEPB7zxJmnJELTCBHPNsTUBVift', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--096c5ca0-1f56-4f7b-99fa-14466d7bfc91-0', usage_metadata={'input_tokens': 33, 'output_tokens': 10, 'total_tokens': 43, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Aden\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! How are you doing today?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Aden\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Aden\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Aden! How can I assist you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Aden\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Philadelphia', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='76', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' commonly', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Six', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' professional', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' basketball', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' based', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Philadelphia', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Pennsylvania', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' compete', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Basketball', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Association', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='NBA', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Eastern', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Atlantic', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Division', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' oldest', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' franchises', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' NBA', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' stor', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ied', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' includes', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' multiple', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' championships', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Fame', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Key', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Points', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='Found', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' History', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' franchise', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' established', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Syracuse', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Nationals', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' became', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' part', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' NBA', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' moved', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Philadelphia', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='196', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' renamed', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='76', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' nod', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' signing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Declaration', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Independence', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Philadelphia', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='177', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='Champ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ionship', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='76', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' three', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' NBA', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' championships', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='195', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Syracuse', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Nationals', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='196', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='7', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='198', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='196', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='7', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Wilt', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Chamber', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='lain', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' often', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' considered', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' greatest', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' teams', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' NBA', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='Not', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='able', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Six', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' legendary', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Wilt', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Chamber', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='lain', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Julius', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='Dr', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' J', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='\"', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Er', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ving', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Moses', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Malone', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Charles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Bark', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ley', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Allen', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Iv', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='erson', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' These', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' left', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' significant', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' mark', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' franchise', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='Recent', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Stars', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' recent', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' stars', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' like', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Joel', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Emb', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='iid', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' until', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' his', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='202', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Ben', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Simmons', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Emb', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='iid', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' particular', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' dominant', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' force', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' his', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' scoring', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' defense', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' charismatic', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' personality', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Process', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Six', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' underwent', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' significant', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' rebuilding', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' phase', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Process', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',\"', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' which', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' involved', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' accumulating', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' draft', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' picks', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' developing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' young', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' talent', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' This', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' strategy', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' while', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' controversial', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' eventually', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' becoming', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' competitive', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' force', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Eastern', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='R', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ival', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='76', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' historic', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' teams', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' like', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Boston', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Celtics', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' New', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' York', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Knicks', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' These', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' fueled', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' playoff', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' battles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' competitive', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' match', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ups', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' over', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='Home', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Arena', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' plays', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' its', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' home', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' games', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Wells', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Fargo', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Center', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' located', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' South', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Philadelphia', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Sports', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Complex', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' Philadelphia', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='76', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' passionate', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' base', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' significant', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' contributions', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' development', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' NBA', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' continue', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' be', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' competitive', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' aspirations', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' adding', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' more', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' championships', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content=' legacy', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'service_tier': 'default', 'model_provider': 'openai'}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709', chunk_position='last')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709', usage_metadata={'input_tokens': 492, 'output_tokens': 487, 'total_tokens': 979, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--ca8f3322-762a-4815-9c5c-e789487f8709', chunk_position='last')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the sixers basketball team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| Philadelphia| |76|ers|,| commonly| known| as| the| Six|ers|,| are| a| professional| basketball| team| based| in| Philadelphia|,| Pennsylvania|.| They| compete| in| the| National| Basketball| Association| (|NBA|)| as| a| member| of| the| league|'s| Eastern| Conference| Atlantic| Division|.| The| team| was| founded| in| |194|6| and| originally| known| as| the| Syracuse| Nationals| before| relocating| to| Philadelphia| in| |196|3|.\n",
      "\n",
      "|###| Key| Points|:\n",
      "\n",
      "|-| **|Arena|**|:| The| |76|ers| play| their| home| games| at| the| Wells| Fargo| Center|,| which| they| share| with| the| NHL|'s| Philadelphia| Flyers|.\n",
      "\n",
      "|-| **|Team| Colors|**|:| The| team's| colors| are| red|,| white|,| and| blue|.\n",
      "\n",
      "|-| **|Masc|ot|**|:| The| |76|ers|'| mascot| is| Franklin| the| Dog|.\n",
      "\n",
      "|-| **|Champ|ionship|s|**|:| The| Six|ers| have| won| three| NBA| championships| (|195|5|,| |196|7|,| and| |198|3|).| The| |196|7| team|,| led| by| Wilt| Chamber|lain|,| is| often| regarded| as| one| of| the| greatest| teams| in| NBA| history|.\n",
      "\n",
      "|-| **|Not|able| Players|**|:| The| franchise| has| been| home| to| several| Hall| of| Fame| players|,| including| Wilt| Chamber|lain|,| Julius| Er|ving| (|Dr|.| J|),| Moses| Malone|,| Charles| Bark|ley|,| and| Allen| Iv|erson|.| These| players| have| left| a| significant| mark| on| the| team's| history| and| the| NBA| as| a| whole|.\n",
      "\n",
      "|-| **|Co|aching| and| Management|**|:| The| team| has| been| led| by| various| notable| coaches| over| the| years|.| As| of| the| |202|3| season|,| the| head| coach| is| Nick| Nurse|,| who| previously| won| an| NBA| championship| with| the| Toronto| Raptors|.\n",
      "\n",
      "|-| **|R|ival|ries|**|:| The| |76|ers| have| historic| rival|ries| with| teams| such| as| the| Boston| Celtics|,| New| York| Knicks|,| and|,| more| recently|,| the| Brooklyn| Nets|.\n",
      "\n",
      "|-| **|Ownership|**|:| The| team| is| owned| by| a| group| led| by| Josh| Harris|,| who| also| has| ownership| stakes| in| other| sports| franchises|.\n",
      "\n",
      "|The| |76|ers| have| a| passionate| fan| base| and| a| stor|ied| history|.| In| recent| years|,| they| have| been| competitive| in| the| Eastern| Conference|,| often| making| playoff| appearances| and| building| around| star| players| like| Joel| Emb|iid|.| The| team| has| been| focused| on| building| a| championship| contender| through| a| combination| of| draft| picks|,| trades|,| and| free|-agent| sign|ings|.||||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the sixers basketball team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectError",
     "evalue": "All connection attempts failed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py:101\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py:78\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connect(request)\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py:124\u001b[39m, in \u001b[36mAsyncHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_backend.connect_tcp(**kwargs)\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpcore\\_backends\\auto.py:31\u001b[39m, in \u001b[36mAutoBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._init_backend()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.connect_tcp(\n\u001b[32m     32\u001b[39m     host,\n\u001b[32m     33\u001b[39m     port,\n\u001b[32m     34\u001b[39m     timeout=timeout,\n\u001b[32m     35\u001b[39m     local_address=local_address,\n\u001b[32m     36\u001b[39m     socket_options=socket_options,\n\u001b[32m     37\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py:113\u001b[39m, in \u001b[36mAnyIOBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    108\u001b[39m exc_map = {\n\u001b[32m    109\u001b[39m     \u001b[38;5;167;01mTimeoutError\u001b[39;00m: ConnectTimeout,\n\u001b[32m    110\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    111\u001b[39m     anyio.BrokenResourceError: ConnectError,\n\u001b[32m    112\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: All connection attempts failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m client = get_client(url=URL)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Search all hosted graphs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m assistants = \u001b[38;5;28;01mawait\u001b[39;00m client.assistants.search()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\langgraph_sdk\\client.py:1124\u001b[39m, in \u001b[36mAssistantsClient.search\u001b[39m\u001b[34m(self, metadata, graph_id, limit, offset, sort_by, sort_order, select, headers, params)\u001b[39m\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m select:\n\u001b[32m   1123\u001b[39m     payload[\u001b[33m\"\u001b[39m\u001b[33mselect\u001b[39m\u001b[33m\"\u001b[39m] = select\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.http.post(\n\u001b[32m   1125\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/assistants/search\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1126\u001b[39m     json=payload,\n\u001b[32m   1127\u001b[39m     headers=headers,\n\u001b[32m   1128\u001b[39m     params=params,\n\u001b[32m   1129\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\langgraph_sdk\\client.py:341\u001b[39m, in \u001b[36mHttpClient.post\u001b[39m\u001b[34m(self, path, json, params, headers, on_response)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m headers:\n\u001b[32m    340\u001b[39m     request_headers.update(headers)\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m r = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.post(\n\u001b[32m    342\u001b[39m     path, headers=request_headers, content=content, params=params\n\u001b[32m    343\u001b[39m )\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_response:\n\u001b[32m    345\u001b[39m     on_response(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpx\\_client.py:1859\u001b[39m, in \u001b[36mAsyncClient.post\u001b[39m\u001b[34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1838\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1840\u001b[39m     url: URL | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1852\u001b[39m     extensions: RequestExtensions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1853\u001b[39m ) -> Response:\n\u001b[32m   1854\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1855\u001b[39m \u001b[33;03m    Send a `POST` request.\u001b[39;00m\n\u001b[32m   1856\u001b[39m \n\u001b[32m   1857\u001b[39m \u001b[33;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(\n\u001b[32m   1860\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1861\u001b[39m         url,\n\u001b[32m   1862\u001b[39m         content=content,\n\u001b[32m   1863\u001b[39m         data=data,\n\u001b[32m   1864\u001b[39m         files=files,\n\u001b[32m   1865\u001b[39m         json=json,\n\u001b[32m   1866\u001b[39m         params=params,\n\u001b[32m   1867\u001b[39m         headers=headers,\n\u001b[32m   1868\u001b[39m         cookies=cookies,\n\u001b[32m   1869\u001b[39m         auth=auth,\n\u001b[32m   1870\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1871\u001b[39m         timeout=timeout,\n\u001b[32m   1872\u001b[39m         extensions=extensions,\n\u001b[32m   1873\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpx\\_client.py:1540\u001b[39m, in \u001b[36mAsyncClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1525\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m   1527\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m   1528\u001b[39m     method=method,\n\u001b[32m   1529\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1538\u001b[39m     extensions=extensions,\n\u001b[32m   1539\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpx\\_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpx\\_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpx\\_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpx\\_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:393\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    160\u001b[39m     value = typ()\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aden\\adenmathew-langgraph-mat496\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: All connection attempts failed"
     ]
    }
   ],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1ef6a3d0-41eb-66f4-a311-8ebdfa1b281f'})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-b5862486-a25f-48fc-9a03-a8506a6692a8', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'example': False} id='f51807de-6b99-4da4-a798-26cf59d16412'\n",
      "=========================\n",
      "content='' additional_kwargs={'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-fa4ab1c6-274d-4be5-8c4a-a6411c7c35cc' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {}, 'status': 'success'} name='multiply' id='3e7bbfb6-aa82-453a-969c-9c753fbd1d74' tool_call_id='call_imZHAw7kvMR2ZeKaQVSlj25C'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-e8e0d672-cfb2-42be-850a-345df3718f69'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1ef6a3da-687f-6253-915a-701de5327165\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "--------------------------------------------------\n",
      "AI: The result\n",
      "--------------------------------------------------\n",
      "AI: The result of\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
